<!DOCTYPE html>
<html>
<head>
<title>Convolutional Anatomy [1/3]</title>
<link href="style.css" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Muli" rel="stylesheet">

</head>
<body>

<h1>CONVOLUTIONAL ANATOMY [1/3]</h1>

<br>
<p>
I stumbled across&nbsp;<a href="https://arxiv.org/pdf/1808.05567.pdf">this paper</a> a few months ago and mostly skimmed through the text, nodding along happily and pretending that the code excerpts didn&#39;t exist. I decided to revisit some of the nitty gritty details recently and realised that code excerpts weren&#39;t gonna cut it; I stood by my trusty whiteboard and drew some blobs until I felt comfortable with it all. If you&#39;re anything like me, then stuff that takes place in any dimension higher than three takes a few iterations of staring at pictures, code, pictures, code to understand.
</p>

<p>
So I&#39;ve decided to write a couple of blog posts, in the style of this&nbsp;<a href="https://cnugteren.github.io/tutorial/pages/page1.html">excellent tutorial</a> on optimising SGEMM (featuring pictures and code) for GPUs.  I&#39;m going to step through all of the algorithms and map them to (hopefully) intuitive diagrams.
</p>

<h2>Naive Direct Convolution</h2>
<p>
Copied directly from the paper, here is the algorithm for direct convolution. This is our starting point, so let&#39;s take some time to understand exactly what&#39;s going on (note also that I&#39;m ignoring strides for now for simplicity).
</p>

<img src='resources/alg1.png' alt='Convolution' style='width:100%;height:auto;'>

<p>
I&#39;ve seen convolution expressed explicitly like this a few times now (usually in codebases it is far less nested) but it still terrifies me. I&#39;ll try to link this with some graphical intuition; I find the most useful thing here to be considering single images in the minibatch, so that&#39;s what I&#39;ll do now.
</p>

<img src='resources/cubes.png' alt='Convolution' style='width:100%;height:auto;'>


<p>
We have a set of K kernels, which form our weights (also sometimes called filters, channels etc.). We convolve each of these K kernels with our input which has spatial dimensions HxW, and C feature maps. Each kernel produces its own feature map, meaning if we have e.g. 5 kernels then our output is PxQx5.
</p>

<p>
Take a second to align these labels with the labels from the algorithm above, and imagine that we have a function that performs 2D convolution for us (e.g. takes a 1x3x3 kernel and convolves it with a 1x224x224 input image.)
</p>

<pre class="para-block pre-fenced pre-fenced3 language-python lang-python python colorized" style="display:block"><code><span style="color:blue">for</span> batch <span style="color:blue">in</span> batches
  <span style="color:blue">for</span> output_channel <span style="color:blue">in</span> <span style="color:purple">K</span>
    <span style="color:blue">for</span> input_channel <span style="color:blue">in</span> <span style="color:purple">C</span>
      do <span class="constant" style="color:purple">2</span><span style="color:purple">D</span> convolution</code></pre>

<p>
During training we often consider batches of N images, but again I&#39;m going to pretty much ignore this for the sake of simplicity for now.
</p>

<p>
Convolution involves sliding the kernel through the input, taking the dot product of all of the elements at each location. For example, for the first kernel, step 1 looks like this:
</p>

<img src='resources/conv1.png' alt='Convolution' style='width:100%;height:auto;'>


<p>
The blue cube is multiplied by the green cube, producing the yellow square on the right.
Then the filter gets moved to the next spatial location:
</p>

<img src='resources/conv2.png' alt='Convolution' style='width:100%;height:auto;'>


<p>
We have taken two dot products so far and you can see that width-wise the kernel can only move two more spaces - this is where P and Q come from. Sometimes, to maintain the size of representations we will perform some padding, but you can go ahead and add that to the list of things I&#39;m not considering for the sake of simplicity.
</p>

<p>
Once we&#39;re done with this kernel, we move on to the next and repeat, until we reach the last kernel:
</p>
<img src='resources/conv3.png' alt='Convolution' style='width:100%;height:auto;'>

<p>
So, now you&#39;ve seen convolution as both pictures and code, I&#39;ll go over it one more time and make the link more explicit.
</p>
<p>
Remember, I&#39;m ignoring batching and leave the extension of these figures as an exercise for the reader ;)
</p>
<p>
At step 1, we iterate over the list of kernels <code class="code code1">K = [k1,k2,...,kK]</code>.
</p>


<img src='resources/step1.png' alt='Convolution' style='width:100%;height:auto;'>


<p>
Since this is the first iteration, we will take the first kernel and move to line 3. The kernels are RxS spatially, with depth C, which means we select c1 from <code class="code code1">C = [c1,c2,...,cC]</code>. We now iterate over each RxS spatial dimension, selecting one at a time:
</p>

<img src='resources/step2.png' alt='Convolution' style='width:100%;height:auto;'>


<p>
Note that the depth of the kernel corresponds to the depth of the input. Next up: how many times should we perform the convolution in the <em class="em-star1">y</em> dimension of the output? I.e. how many times are we going to slide to the right?
</p>

<img src='resources/step3.png' alt='Convolution' style='width:100%;height:auto;'>


<p>
And how many in the <em class="em-star1">x</em> dimension? I.e. how many times are we going to slide down?
</p>

<img src='resources/step4.png' alt='Convolution' style='width:100%;height:auto;'>


<p>
For each of these slides, we are going to need to loop over the 3x3 kernel to get each of the 9 elements. The kernels have a <em class="em-star1">y</em> dimension:
</p>

<img src='resources/step5.png' alt='Convolution' style='width:100%;height:auto;'>


<p>
And finally, an <em class="em-star1">x</em> dimension:
</p>

<img src='resources/step6.png' alt='Convolution' style='width:100%;height:auto;'>


<p>
Probably the most confusing bit of this is <code class="code code1">I[n][c][o_j + r][o_i + s]</code>. Just think that <code class="code code1">o_j</code> and <code class="code code1">o_i</code> give us the top left hand corner of the patch in the image we are convolving with, and <code class="code code1">r</code> and <code class="code code1">s</code> give us offsets in the <em class="em-star1">x</em> and <em class="em-star1">y</em> dimensions.
</p>

<p>
Soo hopefully now you&#39;re familiar with all of the notation and you have some geometric + practical intuition for how convolution is performed directly.
</p>

<p>
Coming up next is vectorisation and register blocking.
</p>

</body>

</html>
